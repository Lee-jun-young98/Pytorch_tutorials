{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5. Torch.autograd를 사용한 자동 미분.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMWvwegI27Hgs6UohhFVO2n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Torch.autograd를 사용한 자동 미분\n","- 신경망을 학습할 때 가장 자주 사용되는 알고리즘은 역전파\n","- 매개변수는 주어진 매개변수에 대한 손실 함수의 변화도(gradient)에 따라 조정\n","- pytorch에서는 torch.autograd라고 불리는 자동 미분 엔진을 사용\n","\n","# 참고\n","https://tutorials.pytorch.kr/beginner/basics/autogradqs_tutorial.html"],"metadata":{"id":"6s1jg8blVvYM"}},{"cell_type":"code","source":["import torch\n","\n","x = torch.ones(5) # input tensor\n","y = torch.zeros(3) # expected output\n","w = torch.randn(5, 3, requires_grad = True)\n","b = torch.randn(3, requires_grad = True)\n","z = torch.matmul(x, w) + b\n","loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"],"metadata":{"id":"HKMqZXi1WCmN","executionInfo":{"status":"ok","timestamp":1647243469186,"user_tz":-540,"elapsed":251,"user":{"displayName":"이준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14894232288140235299"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["print('Gradient function for z =', z.grad_fn)\n","print('Gradient function for loss =', loss.grad_fn)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uQp0JEpNWVK-","executionInfo":{"status":"ok","timestamp":1647244055697,"user_tz":-540,"elapsed":287,"user":{"displayName":"이준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14894232288140235299"}},"outputId":"6b1eb6f3-3a6a-4a01-fa13-67e611a13924"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Gradient function for z = <AddBackward0 object at 0x7f66b93dd910>\n","Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7f66b93dd9d0>\n"]}]},{"cell_type":"markdown","source":["# 변화도 계산하기\n"],"metadata":{"id":"0XTMyfspZZEH"}},{"cell_type":"code","source":["loss.backward()\n","print(w.grad)\n","print(b.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fCg8Jy1wZoKG","executionInfo":{"status":"ok","timestamp":1647244129309,"user_tz":-540,"elapsed":2,"user":{"displayName":"이준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14894232288140235299"}},"outputId":"2ccc4018-d122-4132-f409-3c0024000735"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1164, 0.2347, 0.0559],\n","        [0.1164, 0.2347, 0.0559],\n","        [0.1164, 0.2347, 0.0559],\n","        [0.1164, 0.2347, 0.0559],\n","        [0.1164, 0.2347, 0.0559]])\n","tensor([0.1164, 0.2347, 0.0559])\n"]}]},{"cell_type":"markdown","source":["# 변화도 추적 멈추기\n","- requires_grad = True인모든 텐서들은 연산 기록을 추적하고 변화도 계산 지원\n","- 모델을 학습한 뒤 입력 데이터를 단순히 적용하기만 하는 경우와 같이 순전파 연산만 필요한 경우 추적이나 지원이 필요 없을 수 있음\n","- torch.no_grad() 블록으로 연산 추적 멈출 수 있음"],"metadata":{"id":"QkaP_hZ1ZrAm"}},{"cell_type":"code","source":["z = torch.matmul(x, w) + b\n","print(z.requires_grad)\n","\n","with torch.no_grad():\n","  z = torch.matmul(x, w) + b\n","print(z.requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QA2Dk1daaof9","executionInfo":{"status":"ok","timestamp":1647244410316,"user_tz":-540,"elapsed":4,"user":{"displayName":"이준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14894232288140235299"}},"outputId":"d2449ed7-dfec-484d-f4ae-c8b631de2f8d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n"]}]},{"cell_type":"code","source":["# detach 함수를 사용하여 위의 함수와 동일한 결과를 얻음\n","\n","z = torch.matmul(x, w) + b\n","z_det = z.detach()\n","print(z_det.requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t9YzgVpMavwH","executionInfo":{"status":"ok","timestamp":1647244442691,"user_tz":-540,"elapsed":3,"user":{"displayName":"이준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14894232288140235299"}},"outputId":"9bff1bc1-50f2-445d-c0ed-022574cb38fa"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"markdown","source":["# 선택적으로 읽기(Optional Reading): 텐서 변화도와 야코비안 곱\n"],"metadata":{"id":"xYwIbRHwa3m2"}},{"cell_type":"code","source":["inp = torch.eye(5, requires_grad=True)\n","out = (inp+1).pow(2)\n","out.backward(torch.ones_like(inp), retain_graph = True)\n","print(\"First call\\n\", inp.grad)\n","out.backward(torch.ones_like(inp), retain_graph = True)\n","print(\"\\nSecond call\\n\", inp.grad)\n","inp.grad.zero_()\n","out.backward(torch.ones_like(inp), retain_graph = True)\n","print(\"\\nCall after zeroing gradients\\n\", inp.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjcxxlXSa-A3","executionInfo":{"status":"ok","timestamp":1647244568171,"user_tz":-540,"elapsed":4,"user":{"displayName":"이준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14894232288140235299"}},"outputId":"f2a0c416-c40b-4614-af72-0fdc52f1f52a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["First call\n"," tensor([[4., 2., 2., 2., 2.],\n","        [2., 4., 2., 2., 2.],\n","        [2., 2., 4., 2., 2.],\n","        [2., 2., 2., 4., 2.],\n","        [2., 2., 2., 2., 4.]])\n","\n","Second call\n"," tensor([[8., 4., 4., 4., 4.],\n","        [4., 8., 4., 4., 4.],\n","        [4., 4., 8., 4., 4.],\n","        [4., 4., 4., 8., 4.],\n","        [4., 4., 4., 4., 8.]])\n","\n","Call after zeroing gradients\n"," tensor([[4., 2., 2., 2., 2.],\n","        [2., 4., 2., 2., 2.],\n","        [2., 2., 4., 2., 2.],\n","        [2., 2., 2., 4., 2.],\n","        [2., 2., 2., 2., 4.]])\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"UoV8CSokbWJ3"},"execution_count":null,"outputs":[]}]}